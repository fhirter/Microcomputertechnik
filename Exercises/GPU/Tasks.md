# Übung GPU und Machine Learning

## Lernziele

Die Studierenden

- kennen die aktuellen Entwicklungen in der Prozessorentwicklung.
- können aktuelle Entwicklungen kritisch hinterfragen und konkrete Handlungen im betrieblichen Handlungen ableiten
- kennen den Unterschied zwischen General Purpose CPUs und spezialisierten Co-Prozessoren wie GPU, DSP oder Neural
  Engine.

## Aufgabenstellung

Zum Erreichen der Lernziele sollten die Fragen vollständig beantwortet werden.

Die Antworten sollen in einem kurzen Bericht festgehalten werden.
Dieser Bericht ist am Schluss per E-Mail an den Dozenten einzureichen.
**Die Abgabe ist zwingend**, wird jedoch nicht bewertet.

Es werden folgende formellen Anforderungen gestellt:

- Dateiformat: [Markdown](https://www.markdownguide.org/) oder daraus [generiertes PDF](https://pandoc.org/).
- Diagramme: [PlantUML](https://plantuml.com/de/), [Mermaid](https://mermaid.js.org/) o.ä.

## Fragen

Schaue die folgenden Videos und beantworte jeweils die zugehörigen Fragen.

Diskutiere anschliessend deine Antworten mit einem Klassenkameraden.

[NVIDIA Made a CPU.. I’m Holding It. - Grace CPU/Hopper SuperChip @ Computex 2023](https://www.youtube.com/watch?v=It9D08W8Z7o)
- Welche CPU Architektur nutzen die Nvidia Grace CPUs
- Wiese sind die Grace-Hopper "Superchips" schneller als herkömmliche CPU/GPU Kombinationen?
- Skizziere die Grace-Hopper Systemarchitektur!

[Deep Learning](https://www.youtube.com/watch?v=l42lr8AlrHk)
- Welche grundlegenden Rechenoperationen sind für ML Anwendungen wichtig?
- Wieso können ML Anwendungen so stark parallelisiert werden?

[How GPU Computing Works | GTC 2021](https://www.youtube.com/watch?v=3l10o0DYJXg)
- Wie Unterscheiden sich GPUs von CPUs?
- Wie ermöglichen GPUs die hohe parallele Ausführung von Berechnungen?


## Aufgaben

Löse das folgende Tutorial:

https://github.com/kopytjuk/cuda-tutorial/blob/master/sc11-cuda-c-basics.pdf